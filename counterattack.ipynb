{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dbd422-952b-4d3d-b657-ead51d4e717c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## _A Graph Neural Network deep-dive into successful counterattacks_\n",
    "\n",
    "### 1. Installing the required Python libraries:\n",
    "  Make sure the requirement.txt file is in the directory. Navigate to the directory using command prompt and run\n",
    " ```\n",
    " pip install -r requirements.txt\n",
    " ```\n",
    " or for MacOS\n",
    " ```\n",
    " pip install -r requirements_macos.txt\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fa6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Checkbox, Dropdown, Accordion, VBox\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from spektral.data import Dataset, Graph, DisjointLoader\n",
    "from spektral.layers import CrystalConv, GlobalAvgPool\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import progressbar\n",
    "from os.path import isfile\n",
    "import time\n",
    "\n",
    "# Setting up the logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45961bb5-8f7f-4d9a-8451-279aefc39d07",
   "metadata": {},
   "source": [
    "### 2. Data Processing\n",
    "\n",
    "- `get_data()` fetches the specified file (Women, Men, Combined) from a public s3 bucket. The data is stored locally in {women, men, combined}.pkl. It is automatically loaded after downloading.\n",
    "- We need to convert that data into a Spektral specific `Dataset` class to include node features, edge features and the adjacency matrix. We do this with the `CounterDataset` class that inherits from the `Dataset` class. \n",
    "- The `CounterDataset` class returns a list of `Graph` objects.\n",
    "\n",
    "To help process the data we create a couple interactive checkboxes in 2.2 - 2.6 to help select node features, edge features etc.\n",
    "\n",
    "##### !! For more information on GNN data structures etc. Check out [Spektral's Getting Started](https://graphneural.network/getting-started/) page !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f0b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    '''\n",
    "    Fetches the file from the location, loads it into memory and returns the data.\n",
    "    '''\n",
    "    if not isfile(file_name):\n",
    "        url = f\"https://ussf-ssac-23-soccer-gnn.s3.us-east-2.amazonaws.com/public/counterattack/{file_name}\"\n",
    "\n",
    "        logger.info(f\"Downloading data from {url}...\")\n",
    "        \n",
    "        r = requests.get(url, stream=True)\n",
    "        # Fancy code to print progress bar\n",
    "        block_size = 1024\n",
    "        n_chunk = 1000\n",
    "        file_size = int(r.headers.get('Content-Length', None))\n",
    "        num_bars = np.ceil(file_size / (n_chunk * block_size))\n",
    "        bar =  progressbar.ProgressBar(maxval=num_bars).start()\n",
    "        with open(file_name, 'wb') as f:\n",
    "            for i, chunk in enumerate(r.iter_content(chunk_size=n_chunk * block_size)):\n",
    "                f.write(chunk)\n",
    "                bar.update(i+1)\n",
    "                # Add a little sleep so you can see the bar progress\n",
    "                time.sleep(0.05)\n",
    "\n",
    "        logger.info(\"File downloaded successfully!\")\n",
    "        \n",
    "    logger.info(f\"Opening {file_name}...\")\n",
    "    with open(file_name, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81266f4c-59e7-4002-bbd2-a5ea1f95bebc",
   "metadata": {},
   "source": [
    "### 2.1 Choose Dataset Type\n",
    "\n",
    "Choose the type of file for training the GNN. Options available are women's data (which include women's data from the 2022 NWSL and International women's soccer between 2020 and 2022), men's data (data from the 2022 MLS) and a combined data file (includes both women's and men's data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140c1cf4-e49e-4dcc-b8e0-f043d2da392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose File for training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b59ac8fc7ee493384484de6520afe92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('Women', 'Men', 'Combined'), value='Women')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Choose File for training:\")\n",
    "file_widget = Dropdown(\n",
    "    options=['Women', 'Men', 'Combined'],\n",
    "    value='Women',\n",
    "    disabled=False,\n",
    ")\n",
    "display(file_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e511a5e",
   "metadata": {},
   "source": [
    "### 2.2 (Down)load Data\n",
    "Using the file selection widget we load the appropriate file from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b29edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening women.pkl...\n"
     ]
    }
   ],
   "source": [
    "file_name = file_widget.value.lower() + '.pkl'\n",
    "# Obtain the data\n",
    "og_data = get_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc51426-a03b-443d-8869-5d337b7c05e3",
   "metadata": {},
   "source": [
    "### 2.2 Choose Adjacency Matrix\n",
    "\n",
    "Available options:\n",
    "\n",
    "- **normal** - connects attacking players amongst themselves, defensive players amongst themselves and the attacking and defending players are connected through the ball.\n",
    "- **delaunay** - connects a few attacking players and defending players in a delaunay matrix fashion. Exact layout depends on player positioning during the frame in question.\n",
    "- **dense** - connects all the players and the ball to each other\n",
    "- **dense_ap** - connects all the attacking players to each other and to the defensive players.\n",
    "- **dense_dp** - connects all the defending players to each other and to the attacking players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eab8f50-2704-4900-8137-d5aa8ca30059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose Adjacency Matrix:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b66d09d502245438ca50c31f558d2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('normal', 'delaunay', 'dense', 'dense_ap', 'dense_dp'), value='normal')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Choose Adjacency Matrix:\")\n",
    "adj_matrix = Dropdown(\n",
    "    options=['normal', 'delaunay', 'dense', 'dense_ap', 'dense_dp'],\n",
    "    value='normal',\n",
    "    disabled=False,\n",
    ")\n",
    "display(adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab384df4-477f-404e-875b-322da345cee9",
   "metadata": {},
   "source": [
    "### 2.3 Choose Edge Features\n",
    "\n",
    "Available options:\n",
    "\n",
    "- **Player Distance** - Distance between two players connected to each other\n",
    "- **Speed Difference** - Speed difference between two players connected to each other\n",
    "- **Positional Sine angle** - Sine of the angle created between two players in the edge\n",
    "- **Positional Cosine angle** - Cosine of the angle created between two players in the edge\n",
    "- **Velocity Sine angle** - Sine of the angle created between the velocity vectors of two players in the edge\n",
    "- **Velocity Cosine angle** - Coine of the angle created between the velocity vectors of two players in the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004a8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_dist = Checkbox(\n",
    "    value=True,\n",
    "    description='Player Distance',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "speed_diff_matrix = Checkbox(\n",
    "    value=True,\n",
    "    description='Speed Difference',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "pos_sin_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Positional Sine angle',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "pos_cos_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Positional Cosine angle',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "vel_sin_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Velocity Sine angle',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "vel_cos_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Velocity Cosine angle',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Add the user selection of edge features in edge_f_box list.\n",
    "edge_f_box = VBox([player_dist, speed_diff_matrix, pos_sin_angle, pos_cos_angle, vel_sin_angle, vel_cos_angle])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c0a56",
   "metadata": {},
   "source": [
    "### 2.4 Choose Node Features\n",
    "\n",
    "##### Node Features description\n",
    "- **x coordinate** - x coordinate on the 2D pitch for the player\n",
    "- **y coordinate** - y coordinate on the 2D pitch for the player\n",
    "- **vx** - Velocity vector's x coordinate\n",
    "- **vy** - Velocity vector's y coordinate\n",
    "- **Velocity** - magnitude of the velocity\n",
    "- **Velocity Angle** - angle made by the velocity vector\n",
    "- **Distance to Goal** - distance of the player from the goal post\n",
    "- **Angle with Goal** - angle made by the player with the goal\n",
    "- **Distance to Ball** - distance from the ball (always 0 for the ball)\n",
    "- **Angle with Ball** - angle made with the ball (always 0 for the ball)\n",
    "- **Attacking Team Flag** - 1 if the team is attacking, 0 if not and for the ball\n",
    "- **Potential Receiver** - 1 if player is a potential receiver, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803e4394-862e-41e1-84aa-aaf9987f5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coord = Checkbox(\n",
    "    value=True,\n",
    "    description='x coordinate',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "y_coord = Checkbox(\n",
    "    value=True,\n",
    "    description='y coordinate',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "vx = Checkbox(\n",
    "    value=True,\n",
    "    description='vX',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "vy = Checkbox(\n",
    "    value=True,\n",
    "    description='vY',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "v = Checkbox(\n",
    "    value=True,\n",
    "    description='Velocity',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "velocity_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Velocity Angle',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "dist_goal = Checkbox(\n",
    "    value=True,\n",
    "    description='Distance to Goal',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "goal_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Angle with Goal',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "dist_ball = Checkbox(\n",
    "    value=True,\n",
    "    description='Distance to Ball',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "ball_angle = Checkbox(\n",
    "    value=True,\n",
    "    description='Angle with Ball',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "is_attacking = Checkbox(\n",
    "    value=True,\n",
    "    description='Attacking Team Flag',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "potential_receiver = Checkbox(\n",
    "    value=True,\n",
    "    description='Potential Receiver',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Add the user selection of node features in node_f_box list.\n",
    "node_f_box = VBox([x_coord, y_coord, vx, vy, v, velocity_angle, dist_goal, goal_angle, dist_ball, ball_angle, \n",
    "                is_attacking, potential_receiver])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0104d",
   "metadata": {},
   "source": [
    "### 2.5 Display Checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7481c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5737d73d279454f8766e3bcf8a1cdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(Checkbox(value=True, description='Player Distance'), Checkbox(value=True, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accordion = Accordion(children=[edge_f_box, node_f_box])\n",
    "accordion.set_title(0, 'Edge Features')\n",
    "accordion.set_title(1, 'Node Features')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b48ee9-3aa5-407b-9b7c-f38c9616368f",
   "metadata": {},
   "source": [
    "### 2.6 Update dataset with selected features\n",
    "The loaded dataset is updated to include only the selected node features and edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b8d2bb-6f02-474a-b4b9-c602e2317ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_feature_idxs = [idx for idx, x in enumerate(edge_f_box.children) if x.value]\n",
    "node_feature_idxs = [idx for idx, x in enumerate(node_f_box.children) if x.value]\n",
    "node_features = [x.description for x in node_f_box.children if x.value]\n",
    "\n",
    "# Check for empty edge features or node features.\n",
    "if not any(edge_feature_idxs) and not any(node_feature_idxs):\n",
    "    print(\"\\nCannot have zero edge features and zero node features.\\n\")\n",
    "    print(\"\\nDefaulting to the previous configuration.\")    \n",
    "else:    \n",
    "    og_data[adj_matrix.value]['e'] = [x[:, edge_feature_idxs] for x in og_data[adj_matrix.value]['e']]\n",
    "    og_data[adj_matrix.value]['x'] = [x[:, node_feature_idxs] for x in og_data[adj_matrix.value]['x']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b04b5",
   "metadata": {},
   "source": [
    "### 2.7 Convert to Spektral Graphs\n",
    "Finally, we convert the data to Spektrals `Graph` representation. We also select the adjecancy matrix type.\n",
    "\n",
    "##### !! [More information on creating custom datasets with Spektal](https://graphneural.network/creating-dataset/) !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a32e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Convert raw Graph data to a CounterDataset with Dataset class from the spektral library to include node features, \n",
    "    edge features and the adjacency matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "        Constructor to load parameters.\n",
    "        '''\n",
    "        self.og_data = kwargs['og_data']\n",
    "        self.matrix_type = kwargs['matrix_type']\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def read(self):\n",
    "        '''\n",
    "        Overriding the read function - to return a list of Graph objects\n",
    "        '''\n",
    "        logger.info(\"Loading Pass Dataset.\")\n",
    "        \n",
    "        data = self.og_data\n",
    "        # Choosing the data with the required matrix type.\n",
    "        data_mat = data[self.matrix_type]\n",
    "        \n",
    "        # Print Graph information\n",
    "        logger.info(\n",
    "            f\"\"\"node_features (x): {data_mat['x'][0].shape}\n",
    "             \\n adj_matrix (a): {data_mat['a'][0].shape}\n",
    "             \\n edge_features (e): {data_mat['e'][0].shape}\n",
    "             \"\"\"\n",
    "        )\n",
    "        \n",
    "        # Return a list of Graph objects\n",
    "        return [\n",
    "            Graph(x=x, a=a, e=e, y=y) for x, a, e, y in zip(\n",
    "                data_mat['x'], data_mat['a'], data_mat['e'], data['binary']\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d45b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pass Dataset.\n",
      "node_features (x): (23, 9)\n",
      "             \n",
      " adj_matrix (a): (23, 23)\n",
      "             \n",
      " edge_features (e): (287, 2)\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset in the CounterDataset format.\n",
    "dataset = CounterDataset(og_data = og_data, matrix_type = adj_matrix.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a787da2-6592-4445-8e16-5eba2ed869a9",
   "metadata": {},
   "source": [
    "### 3 Training Graph Neural Network\n",
    "\n",
    "### 3.1 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861944d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 150  # Number of training epochs\n",
    "batch_size = 16  # Batch size\n",
    "channels = 128  # Hidden units for the neural network\n",
    "layers = 3  # Number of CrystalConv layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c3dc9",
   "metadata": {},
   "source": [
    "### 3.2 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8224411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 4348\n",
      "Pct successful total: 0.5\n",
      "Pct successful train: 0.5\n",
      "Pct successful test: 0.53\n"
     ]
    }
   ],
   "source": [
    "N = max(g.n_nodes for g in dataset) # Number of nodes\n",
    "F = dataset.n_node_features  # Dimension of node features\n",
    "S = dataset.n_edge_features  # Dimension of edge features\n",
    "n_out = dataset.n_labels  # Dimension of the target\n",
    "n = len(dataset) # Number of samples in the dataset\n",
    "\n",
    "# Train/test split for the dataset\n",
    "idxs = np.random.RandomState(seed=15).permutation(len(dataset))\n",
    "split_va, split_te = int(0.7 * len(dataset)), int(0.69 * len(dataset))\n",
    "idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "dataset_tr = dataset[idx_tr]\n",
    "dataset_te = dataset[idx_te]\n",
    "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
    "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1, shuffle = False)\n",
    "\n",
    "# Display dataset information on target variable.\n",
    "logger.info(f\"n: {n}\")\n",
    "logger.info(f\"Pct successful total: {round(np.asarray([graph.y[0] for graph in dataset]).sum() / n, 2)}\")\n",
    "logger.info(f\"Pct successful train: {round(np.asarray([graph.y[0] for graph in dataset_tr]).sum() / (n * .7), 2)}\")\n",
    "logger.info(f\"Pct successful test: {round(np.asarray([graph.y[0] for graph in dataset_te]).sum() / (n * .3), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d780a4d",
   "metadata": {},
   "source": [
    "### 3.3 Build GNN Model\n",
    "Build the GNN model using the Spektral preferred structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0473cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(Model):\n",
    "    '''\n",
    "    Building the Graph Neural Network configuration with Model as the parent class \n",
    "    from spektral library.\n",
    "    '''\n",
    "    def __init__(self, n_layers):\n",
    "        '''\n",
    "        Constructor code for setting up the layers needed for training the model.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.conv1 = CrystalConv()\n",
    "        self.convs = []\n",
    "        for _ in range(1, n_layers):\n",
    "            self.convs.append(\n",
    "                CrystalConv()\n",
    "            )\n",
    "        self.pool = GlobalAvgPool()\n",
    "        self.dense1 = Dense(channels, activation=\"relu\")\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense2 = Dense(channels, activation=\"relu\")\n",
    "        self.dense3 = Dense(n_out, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        Build the neural network.\n",
    "        '''\n",
    "        x, a, e, i = inputs\n",
    "        x = self.conv1([x, a, e])\n",
    "        for conv in self.convs:\n",
    "            x = conv([x, a, e])\n",
    "        x = self.pool([x, i])\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = GNN(layers)\n",
    "# Setup the optimizer\n",
    "optimizer = Adam(learning_rate)\n",
    "# Set up the logloss function\n",
    "loss_fn = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deffde8",
   "metadata": {},
   "source": [
    "### 3.4 Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a28b09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'CounterDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n",
      "C:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.4700345993042\n",
      "Loss: 1.1173301935195923\n",
      "Loss: 0.8093712329864502\n",
      "Loss: 0.75190669298172\n",
      "Loss: 0.7196800708770752\n",
      "Loss: 0.7044999003410339\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader_tr:\n\u001b[0;32m     14\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 15\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m loader_tr\u001b[38;5;241m.\u001b[39msteps_per_epoch:\n\u001b[0;32m     17\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2492\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2714\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2690\u001b[0m \u001b[38;5;124;03m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[0;32m   2691\u001b[0m \n\u001b[0;32m   2692\u001b[0m \u001b[38;5;124;03m`args` and `kwargs` can be None if this `Function` was created with an\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2710\u001b[0m \u001b[38;5;124;03m    shape relaxation retracing.\u001b[39;00m\n\u001b[0;32m   2711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2713\u001b[0m   args, kwargs, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 2714\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2716\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function_spec.py:432\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m   filtered_flat_inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m filtered_flat_kwargs\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_inputs_to_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_input_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(flat_inputs)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, kwargs, filtered_flat_inputs\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function_spec.py:519\u001b[0m, in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(spec, tensor_spec\u001b[38;5;241m.\u001b[39mTensorSpec) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m _pywrap_utils\u001b[38;5;241m.\u001b[39mIsTensor(value)):\n\u001b[0;32m    518\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 519\u001b[0m     flatten_inputs[index] \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     need_packing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    522\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1621\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m preferred_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1620\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1621\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1623\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;66;03m# Could not coerce the conversion to use the preferred dtype.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mC:\\ussf_github\\ussf_ssac_23_soccer_gnn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
    "def train_step(inputs, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Print loss at each step of training.\n",
    "step = loss = 0\n",
    "for batch in loader_tr:\n",
    "    step += 1\n",
    "    loss += train_step(*batch)\n",
    "    if step == loader_tr.steps_per_epoch:\n",
    "        step = 0\n",
    "        print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
    "        loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcc639-9591-4d05-bb73-bb5ed6f5fcf7",
   "metadata": {},
   "source": [
    "### 4 Evaluate Model Performance\n",
    "\n",
    "### 4.1 Evaluate ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d43864",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Testing Model...\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Add the true values and the predicted values in the list\n",
    "for batch in loader_te:\n",
    "    inputs, target = batch\n",
    "    p = model(inputs, training=False)\n",
    "    y_true.append(target)\n",
    "    y_pred.append(p.numpy())\n",
    "\n",
    "# Calculate the ROC-AUC metric\n",
    "y_true = np.vstack(y_true)\n",
    "y_pred = np.vstack(y_pred)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC w/ True positive rate on the y-axis and False positive rate on the x-axis.\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3136873-57bf-4b0a-bd99-032a1924fa5b",
   "metadata": {},
   "source": [
    "### 4.2 Evaluate Calibration\n",
    "- Calculate Expected Calibration Error\n",
    "- Plot Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa11b4-0a69-4e58-8cd6-bdd049540c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataset in the CounterDataset format.\n",
    "dataset_c = CounterDataset(og_data = og_data, matrix_type = adj_matrix.value)\n",
    "\n",
    "# Setup the loader.\n",
    "loader = DisjointLoader(dataset_c, batch_size=1, epochs=1, shuffle = False)\n",
    "\n",
    "# Set up an empty pandas dataframe.\n",
    "ece_df = pd.DataFrame(columns = ['output_pp', 'predicted', 'target', 'result'])\n",
    "\n",
    "# Compute the predictions and save them in the Pandas DataFrame.\n",
    "for batch in loader:\n",
    "    inputs, target = batch\n",
    "    p = model(inputs, training=False)\n",
    "    original_prediction = p.numpy()[0][0]\n",
    "    \n",
    "    # Threshold set to 0.5\n",
    "    predicted_value = 1 if original_prediction >= 0.5 else 0 \n",
    "    ece_df.loc[len(ece_df)] = [original_prediction, predicted_value, target[0][0], 1 if predicted_value == target[0][0] else 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d87aba-0718-48dd-affa-a231b7d46f97",
   "metadata": {},
   "source": [
    "##### Expected Calibration Error (ECE)\n",
    "\n",
    "$$ ECE = \\sum_{k = 1}^{K} \\frac{|B_k|}{N}  \\left| \\left( \\frac{1}{|B_k|} \\sum_{i \\in B_k} y_i \\right) - \\left( \\frac{1}{|B_k|} \\sum_{i \\in B_k} \\hat{y_i} \\right) \\right| $$\n",
    "\n",
    "We distribute the outcome into K bins, and compute the difference between the average prediction in each bin and the average expected outcome for the examples in each bin. $B_k$ corresponds to the set of examples in the $k$-th bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00927f4-f8d5-4510-bac9-f19ad585a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the bins\n",
    "bin_ranges = [(0, 0.1), (0.1, 0.2), (0.2, 0.3), (0.3, 0.4), (0.4, 0.5), (0.5, 0.6), (0.6, 0.7), (0.7, 0.8), (0.8, 0.9), (0.9, 1.0)]\n",
    "bin_calc = pd.DataFrame(columns = ['bin', 'count', 'accuracy', 'avg_pp', 'acc-conf', 'count_into_acc-conf'])\n",
    "\n",
    "for i, bin_range in enumerate(bin_ranges):\n",
    "    # Get the higher and lower end of the bins\n",
    "    lower, higher = bin_range[0], bin_range[1]\n",
    "    \n",
    "    # Get the probability outputs within the range\n",
    "    bin_calc_temp = ece_df.loc[(ece_df['output_pp'] > lower) & (ece_df['output_pp'] <= higher)]\n",
    "    count = bin_calc_temp.shape[0]\n",
    "    \n",
    "    # Compute parameters needed to calculate ECE \n",
    "    if count > 0:\n",
    "        total_corrects = bin_calc_temp[(bin_calc_temp['result'] == 1)].shape[0]\n",
    "        accuracy = total_corrects / count\n",
    "        avg_pp = bin_calc_temp['output_pp'].mean()\n",
    "        acc_conf = abs(accuracy - avg_pp)\n",
    "\n",
    "        bin_calc.loc[i] = [bin_range, count, accuracy, avg_pp, acc_conf, count*acc_conf]\n",
    "        \n",
    "# Print ECE value    \n",
    "print(\"ECE is : \" + str(bin_calc['count_into_acc-conf'].sum() / bin_calc['count'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ec56d",
   "metadata": {},
   "source": [
    "##### Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sklearn calibration_curve() function to obtain calibration values for the model.\n",
    "cal_y, cal_x = calibration_curve(ece_df['target'], ece_df['output_pp'], n_bins = 10)\n",
    "\n",
    "# Plot the calibration curve.\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(cal_x, cal_y, marker = '.')\n",
    "plt.plot([0, 1], [0, 1], ls = '--', color = 'green', label = 'Ideal calibration')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48510897-d344-4bcf-8c3f-e3080a8ae3c0",
   "metadata": {},
   "source": [
    "### 5. Measure Feature Importance\n",
    "\n",
    "[Permutation Feature Importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html) ([Altmann & Tolosi, 2010](https://www.researchgate.net/publication/43130914_Permutation_importance_A_corrected_feature_importance_measure)) allows us to identify the importance of each individual feature by measuring the increase in prediction error when breaking the relationship between individual features and the observed result through the application of a random permutation to the featureâ€™s values. In other words, we use the test set to randomly shuffle the values for one feature and recalculate the model error.\n",
    "\n",
    "To do this we create a new dataset were the feature of either the attacking team or the defending team are shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4f2b5-6047-4538-8dd7-e33bcf25d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledCounterDataset(Dataset):\n",
    "    '''\n",
    "    Convert raw Graph data to a ShuffledCounterDataset with Dataset class from the spektral library to include node features, \n",
    "    edge features and the adjacency matrix.\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "        Constructor to load the parameters.\n",
    "        '''\n",
    "        self.og_data = kwargs['og_data']\n",
    "        self.node_feature_shuffle = kwargs['node_feature_shuffle']\n",
    "        self.player_type = kwargs['player_type']\n",
    "        self.matrix_type = kwargs['matrix_type']\n",
    "        self.flag_index = kwargs['flag_index']\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def read(self):\n",
    "        '''\n",
    "        Overriding the read function - to return a list of Graph objects.\n",
    "        Permuting the features in this function.\n",
    "        '''\n",
    "        data = copy.deepcopy(self.og_data)\n",
    "        data_mat = data[self.matrix_type]\n",
    "        \n",
    "        # Check the type of players to be shuffled\n",
    "        if self.player_type == 'attacking':\n",
    "            for i in range(len(data_mat['x'])):\n",
    "                arr = data_mat['x'][i]\n",
    "                  \n",
    "                # Get the appropriate type of player\n",
    "                atts = arr[0:-1][arr[:-1, self.flag_index] == 1].copy()\n",
    "                defs = arr[0:-1][arr[:-1, self.flag_index] == 0].copy()\n",
    "                ball = arr[-1].copy()\n",
    "\n",
    "                # Shuffle the feature requested\n",
    "                random.shuffle(atts[:, self.node_feature_shuffle])\n",
    "\n",
    "                # Assign back the shuffled values to the correct place they came from\n",
    "                arr[0:-1][arr[:-1, self.flag_index] == 1] = atts\n",
    "                arr[0:-1][arr[:-1, self.flag_index] == 0] = defs\n",
    "           \n",
    "        else:\n",
    "            for i in range(len(data_mat['x'])):\n",
    "                arr = data_mat['x'][i]\n",
    "                    \n",
    "                # Get the appropriate type of player\n",
    "                atts = arr[0:-1][arr[:-1, self.flag_index] == 1].copy()\n",
    "                defs = arr[0:-1][arr[:-1, self.flag_index] == 0].copy()\n",
    "                ball = arr[-1].copy()\n",
    "\n",
    "                # Shuffle the feature requested\n",
    "                random.shuffle(defs[:, self.node_feature_shuffle])\n",
    "\n",
    "                # Assign back the shuffled values to the correct place they came from\n",
    "                arr[0:-1][arr[:-1, self.flag_index] == 1] = atts\n",
    "                arr[0:-1][arr[:-1, self.flag_index] == 0] = defs\n",
    "        \n",
    "        \n",
    "        return [\n",
    "            Graph(x=x, a=a, e=e, y=y) for x, a, e, y in zip(data_mat['x'], data_mat['a'], data_mat['e'], data['binary'])\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f511ff-fbfa-429f-8939-fa6ab71d491c",
   "metadata": {},
   "source": [
    "#### Select Attack or Defense for Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe9ae0-a3cc-4203-b9cb-54351ee69f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose feature importance\n",
    "print(\"Choose Player type for testing feature importance:\")\n",
    "player_type = Dropdown(\n",
    "    options=['Attacking', 'Defending'],\n",
    "    value='Attacking',\n",
    "    disabled=False,\n",
    ")\n",
    "display(player_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5b6fd-fb55-4906-8446-3998afcf5c5f",
   "metadata": {},
   "source": [
    "#### Shuffle the node features & Change the number of random shuffling iterations we want to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0caaf-05b2-4164-b33c-624683e4a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = [] # Empty list to store the AUC values\n",
    "feature_dict = {} # Feature dictionary to store the feature change values\n",
    "flag_found = False # Flag to check if Attacking Team feature is included in training\n",
    "iterations = 10 # Number of iterations\n",
    "\n",
    "# Check if Attacking Team Flag exists\n",
    "for flag_index, feature in enumerate(node_features):\n",
    "    if feature == 'Attacking Team Flag':\n",
    "        flag_found = True\n",
    "        break\n",
    "\n",
    "# If Attacking Team Flag does not exist - feature importance can't be performed.\n",
    "if not flag_found:\n",
    "    print(\"Attacking team Flag not included in node features. Can't compute feature importance.\")\n",
    "    \n",
    "else:\n",
    "    for i in range(len(node_features)): \n",
    "        mini_auc = []\n",
    "        for _ in range(iterations):\n",
    "            # Get shuffled data\n",
    "            shuffle_data = ShuffledCounterDataset(og_data = og_data,\n",
    "                                          node_feature_shuffle = i, player_type = player_type.value.lower(), \n",
    "                                          matrix_type = adj_matrix.value, flag_index = flag_index)\n",
    "            \n",
    "            # Split between training and testing data\n",
    "            idxs = np.random.RandomState(seed=35).permutation(len(shuffle_data))\n",
    "            split_va, split_te = int(0.7 * len(dataset)), int(0.7 * len(shuffle_data))\n",
    "            idx_tr, idx_va, idx_te = np.split(idxs, [split_va, split_te])\n",
    "            dataset_tr = shuffle_data[idx_tr]\n",
    "            dataset_va = shuffle_data[idx_va]\n",
    "            dataset_te = shuffle_data[idx_te]\n",
    "            loader_te = DisjointLoader(dataset_te, batch_size=16, epochs=1)\n",
    "\n",
    "            # Obtain the model metrics\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            for batch in loader_te:\n",
    "                inputs, target = batch\n",
    "                p = model(inputs, training=False)\n",
    "                y_true.append(target)\n",
    "                y_pred.append(p.numpy())\n",
    "\n",
    "            y_true = np.vstack(y_true)\n",
    "            y_pred = np.vstack(y_pred)\n",
    "            fpr, tpr, threshold = metrics.roc_curve(y_true, y_pred)\n",
    "            roc_auc = metrics.auc(fpr, tpr)\n",
    "            # Store the AUC's at all iterations\n",
    "            mini_auc.append(roc_auc)\n",
    "\n",
    "        # Perform the error calculation and store it in the aucs list.\n",
    "        errors = [1 - auc_1 for auc_1 in mini_auc]\n",
    "        main_error = 1 - roc_auc\n",
    "        errors_ = [100*(error - main_error) for error in errors]\n",
    "        feature_dict[node_features[i]] = errors_\n",
    "        aucs.append(sum(mini_auc) / len(mini_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eee694-0802-4d60-ab96-9f309aa0ce5e",
   "metadata": {},
   "source": [
    "#### Box plot to inspect feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad4488-2cd7-4d98-8ac2-1fa56792a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,25))\n",
    "\n",
    "box_plot = plt.boxplot(feature_dict.values(),\n",
    "                               positions=np.array(\n",
    "    np.arange(len(feature_dict.keys())))*2.0+0.3,\n",
    "                               widths=0.6, vert = False)\n",
    "    \n",
    "    \n",
    "def define_box_properties(plot_name, color_code = 'black', label = ''):\n",
    "    '''\n",
    "    Define Box plot properties.\n",
    "    '''\n",
    "    for k, v in plot_name.items():\n",
    "        plt.setp(plot_name.get(k), color=color_code)\n",
    "         \n",
    "    # use plot function to draw a small line to name the legend.\n",
    "    plt.plot([], c=color_code, label=label)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "define_box_properties(box_plot)\n",
    "\n",
    "plt.yticks(np.arange(0, len(feature_dict.keys()) * 2, 2), feature_dict.keys())\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title('Feature Importance - Box Plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
